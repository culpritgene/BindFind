{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "from collections import defaultdict\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from types import MethodType\n",
    "from pytorch_lightning.callbacks import LearningRateLogger, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (17, 8);\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils import *\n",
    "from config import *\n",
    "from datasets import DoubleMotifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hparams(epochs=100, second_hidden=32, learning_rate=3e-4,\n",
    "                 grouped_lr=False, weight_decay=0, batch_size=48, warmup=0.25, lr_multiplier=1, scheduler=False):\n",
    "    ### model dimensions\n",
    "    hparams = {'input_dim1':len(AmEnc), 'input_dim2':len(NucEnc), \n",
    "               'main_hidden1':112, 'main_hidden2':96, 'second_hidden':second_hidden, 'groups':4}\n",
    "    \n",
    "    ### trainig\n",
    "    hparams.update({'epochs':epochs, 'Positive_rate':0.5, 'batch_size':batch_size})\n",
    "    \n",
    "    ### transforms \n",
    "    hparams.update({'FIXED_LEN':100, 'PREFIX_prob':0.3, 'MAX_ROLL':25, 'ROLL_prob':0.2})\n",
    "    \n",
    "    ### paths\n",
    "    hparams.update({'train_data':'../Data/small_Train_particle_0.csv',\n",
    "               'val_data':'../Data/small_Val_particel_0.csv',\n",
    "               'test_data':'../Data/small_Test_particle.csv'})\n",
    "    \n",
    "    ### optimizers\n",
    "    hparams['optimizer'] = {}\n",
    "    hparams['optimizer']['learning_rate'] = learning_rate\n",
    "    hparams['optimizer']['weight_decay'] = weight_decay\n",
    "\n",
    "    hparams['optimizer']['grouped_lr'] = False\n",
    "    param_groups = defaultdict(lambda: {})\n",
    "    param_groups['ProteinEncoder']['lr'] = 'Freeze'\n",
    "    param_groups['DNAEncoder']['lr'] = 'Freeze'\n",
    "    hparams['optimizer']['param_groups'] = dict(param_groups)\n",
    "    if not scheduler:\n",
    "        hparams['scheduler'] = False\n",
    "    else:\n",
    "        hparams['scheduler'] = {'pct_start':warmup, 'div_factor':20,\n",
    "                               'final_div_factor':800, 'anneal_strategy':'cos',\n",
    "                                'steps_per_epoch':60*32//batch_size,\n",
    "                                'epochs':hparams['epochs']}\n",
    "\n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = make_hparams(epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = COUPLER(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,y,s,idx = next(iter(M.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = M(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6369], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trainer(i, epochs, name='SatgeI_small_baseline', version='v1'):\n",
    "    early_stopping = EarlyStopping('val_loss', min_delta=0.003, patience=3)\n",
    "    tmpdir = '/home/moonstrider/Bioinfo/DNA_to_Protein_Motifs/BindFind/chkpt/'\n",
    "    tb_logger = pl.loggers.TensorBoardLogger('lightning_logs', name=name, version=version)\n",
    "    model_chekpoint = ModelCheckpoint(os.path.join(tmpdir, f'small_baseline_cross_val_{i}'+'-{epoch}-{val_loss:.2f}'), \n",
    "                                      verbose=True, period=5, save_top_k=5)\n",
    "    \n",
    "    trainer = pl.Trainer(max_epochs=100, gradient_clip=0.5, logger=tb_logger, gpus=1, \n",
    "                         callbacks=[early_stopping], checkpoint_callback=model_chekpoint,\n",
    "                     show_progress_bar=False)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPasramsList = [copy.deepcopy(hparams) for _ in range(5)]\n",
    "for i, hp in enumerate(HPasramsList):\n",
    "    hp['train_data'] = hp['train_data'].replace('0', f'{i}')\n",
    "    hp['val_data'] = hp['val_data'].replace('0', f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run training in cross validation\n",
    "for i, hp in enumerate(HPasramsList):\n",
    "    M = COUPLER(hparams=hp)\n",
    "    trainer = build_trainer(i, epochs=M.hparams['epochs'], name='Velaciraptor', version='crossVal'+str(i))\n",
    "    trainer.fit(M)\n",
    "    del M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iDS",
   "language": "python",
   "name": "ids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
